{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18-11-2023 - 4\r"
     ]
    }
   ],
   "source": [
    "### Ana mantık şöyle işliyor. Son dakika haberleri gün gün ve sayfa sayfa giriliyor. En çok okunan haberlerin sayısı ise genellikle 5\n",
    "### O yüzden bugünun tarihinden geriye doğru gidiyoruz. Eğer haber sayısı 5'e eşit olursa loop kırılıyor\n",
    "### Böylece her gün yayınlanan haberleri buluyor bunu bir DataFrame üzerinden bir .csv dosyasına kaydediyoruz\n",
    "### Sonrasında linkleri teker teker indiriyoruz.\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for day in range(0,365):\n",
    "    for page in range(1,10):\n",
    "            ### Hangi gün hangi sayfada olduğumuzu print ediyoruz\n",
    "            print(f'{(datetime.today()- timedelta(days=day)).strftime(\"%d-%m-%Y\")} - {page}', end='\\r')\n",
    "            ### Url'yi oluşturuyoruz\n",
    "            url = f'https://www.ekonomim.com/son-dakika-haberleri?date={(datetime.today()- timedelta(days=day)).strftime(\"%d-%m-%Y\")}&sayfa={page}'\n",
    "            ### Sayfayı indiriyoruz\n",
    "            response = requests.get(url)  # url of next page\n",
    "            ### Html formatına getiriyoruz\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            ### Linkleri çıkartıyoruz\n",
    "            newslist = soup.find_all(\"div\", {\"class\": \"container category-page\"})\n",
    "            ### İçinde sayfa numarası olan linklerden kurtuluyoruz ve yalnızca https içerikli linkleri alıyoruz\n",
    "            newslinks = []\n",
    "            for item in newslist:\n",
    "                for link in item.find_all('a', href=True):\n",
    "                    if 'sayfa=' in link['href']: \n",
    "                        continue\n",
    "                    elif 'https' in link['href']:\n",
    "                        newslinks.append(link['href'])\n",
    "            newslinks = list(set(newslinks))\n",
    "            ### Eğer o sayfadaki link sayısı 5 ise, Çok okunanların sayısı, loop kırılıyor ve diğer tarihe geçiyoruz\n",
    "            if len(newslinks)  == 5:\n",
    "                break\n",
    "            else: \n",
    "                a = pd.DataFrame({\n",
    "                    'Tarih': (datetime.today()- timedelta(days=999)).strftime(\"%d-%m-%Y\"),\n",
    "                    'Link' : newslinks\n",
    "                })\n",
    "                df = pd.concat([df,a])\n",
    "### Tekrar eden linklerden, Çok okunanlardan, kurtuluyoruz\n",
    "df = df.drop_duplicates().reset_index(drop=True)      \n",
    "### Kaydediyoruz\n",
    "df.to_csv('base_news.csv', encoding='utf-8', index=False)      \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dosyayı Oku\n",
    "df = pd.read_csv('./base_news.csv') \n",
    "### Haber linklerindeki metni indirip bir dosyaya kaydet.\n",
    "### Buradaki range'i len(df) ile değiştirmek lazım\n",
    "for r in range(0,100):\n",
    "    ### Data Frame'deki linki al\n",
    "    url = df['Link'][r]\n",
    "    response = requests.get(url)  # url of next page\n",
    "    soup = BeautifulSoup(response.content, 'html.parser'),\n",
    "    ### Haber metnini indir ve texte dönüştür\n",
    "    news = soup[0].find_all(\"div\", {\"class\": \"content-text\"})\n",
    "    news2 = news[0].text\n",
    "    ### Kaydet\n",
    "    f = open(f\"./News/{df['Tarih'][r] + '_' +url.split('/')[len(url.split('/'))-1][:24]}.txt\", \"a\", encoding=\"utf-8\")\n",
    "    f.write(news2)\n",
    "    f.close()\n",
    "    ### İşlemin yüzde kaçında olduğumuzu print ettir.\n",
    "    print(round(r/100*100,2), end='\\r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
